{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python382jvsc74a57bd0aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49",
   "display_name": "Python 3.8.2 64-bit"
  },
  "interpreter": {
   "hash": "f97131cf564dea1b0b4b8dbe764d683d5aa939e714f8d97fad2a12f3d10ed845"
  },
  "metadata": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## tranfer learning (전이 학습)\n",
    "## transferlearning_001.ipynb "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### 최소한의 노력으로 최대의 효과를 얻고자 하는 것이 목표\n",
    "#### pypi.org에서 수많은 라이브러리가 있는 것처럼,\n",
    "#### 분명히 다른 사람이 내가 하고자 하는 작업에 적합한 모델을 만드는데 시간을 보냈을꺼야!\n",
    "#### 누군가가 딥러닝을 위해 모델을 이미 만들어서 존재한다.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "[tensorflow hub](https://tfhub.dev/) : 기존 모델 구성 요소를 위한 저장소\n",
    "\n",
    "#### 전이 학습을 사용하면, 원래 데이터의 10%만 사용하여 지금까지 최고의 모델이 얻은 것과 동일한 결과를 얻을 수 있다.\n",
    "\n",
    "#### 우리가 지난주에 한 것처럼 1개의 클래스에 750개 정도의 이미지가 있어도 좋으련만... \n",
    "#### 이미지는 구하기도 어렵고, 구하는 시간도 오래 걸립니다. 이미지를 구할 때 귀찮으면 bias가 생길 수도 있다. (내가 좋은 결과를 얻고자 하는 이미지만 보려고 한다)\n",
    "#### 시간은 없고, 돈도 없고, 이미지는 75개 정도만 있는데 결과를 빨리 얻고 싶은데..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "zip_ref = zipfile.ZipFile(\"10_food_classes_10_percent.zip\", \"r\")\n",
    "zip_ref.extractall()\n",
    "zip_ref.close()\n",
    "\n",
    "# 10_food_classes_10_percent 라는 폴더가 생성됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10_food_classes_10_percent 폴더에는 2개의 폴더와 0개의 파일이 존재합니다.\n10_food_classes_10_percent/test 폴더에는 10개의 폴더와 0개의 파일이 존재합니다.\n10_food_classes_10_percent/test/ice_cream 폴더에는 0개의 폴더와 250개의 파일이 존재합니다.\n10_food_classes_10_percent/test/chicken_curry 폴더에는 0개의 폴더와 250개의 파일이 존재합니다.\n10_food_classes_10_percent/test/steak 폴더에는 0개의 폴더와 250개의 파일이 존재합니다.\n10_food_classes_10_percent/test/sushi 폴더에는 0개의 폴더와 250개의 파일이 존재합니다.\n10_food_classes_10_percent/test/chicken_wings 폴더에는 0개의 폴더와 250개의 파일이 존재합니다.\n10_food_classes_10_percent/test/grilled_salmon 폴더에는 0개의 폴더와 250개의 파일이 존재합니다.\n10_food_classes_10_percent/test/hamburger 폴더에는 0개의 폴더와 250개의 파일이 존재합니다.\n10_food_classes_10_percent/test/pizza 폴더에는 0개의 폴더와 250개의 파일이 존재합니다.\n10_food_classes_10_percent/test/ramen 폴더에는 0개의 폴더와 250개의 파일이 존재합니다.\n10_food_classes_10_percent/test/fried_rice 폴더에는 0개의 폴더와 250개의 파일이 존재합니다.\n10_food_classes_10_percent/train 폴더에는 10개의 폴더와 0개의 파일이 존재합니다.\n10_food_classes_10_percent/train/ice_cream 폴더에는 0개의 폴더와 75개의 파일이 존재합니다.\n10_food_classes_10_percent/train/chicken_curry 폴더에는 0개의 폴더와 75개의 파일이 존재합니다.\n10_food_classes_10_percent/train/steak 폴더에는 0개의 폴더와 75개의 파일이 존재합니다.\n10_food_classes_10_percent/train/sushi 폴더에는 0개의 폴더와 75개의 파일이 존재합니다.\n10_food_classes_10_percent/train/chicken_wings 폴더에는 0개의 폴더와 75개의 파일이 존재합니다.\n10_food_classes_10_percent/train/grilled_salmon 폴더에는 0개의 폴더와 75개의 파일이 존재합니다.\n10_food_classes_10_percent/train/hamburger 폴더에는 0개의 폴더와 75개의 파일이 존재합니다.\n10_food_classes_10_percent/train/pizza 폴더에는 0개의 폴더와 75개의 파일이 존재합니다.\n10_food_classes_10_percent/train/ramen 폴더에는 0개의 폴더와 75개의 파일이 존재합니다.\n10_food_classes_10_percent/train/fried_rice 폴더에는 0개의 폴더와 75개의 파일이 존재합니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(\"10_food_classes_10_percent\"):\n",
    "    print(f\"{dirpath} 폴더에는 {len(dirnames)}개의 폴더와 {len(filenames)}개의 파일이 존재합니다.\")\n",
    "\n",
    "# 학습은 지난번보다 10%의 데이터로 하고, 테스트는 원래의 양과 같이 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "학습 이미지 : \n",
      "Found 750 images belonging to 10 classes.\n",
      "테스트 이미지 : \n",
      "Found 2500 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# 데이터가 준비가 된 상태입니다.\n",
    "# 데이터를 분석할 준비하기\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "IMAGE_SHAPE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dir = \"10_food_classes_10_percent/train/\"\n",
    "test_dir = \"10_food_classes_10_percent/test/\"\n",
    "\n",
    "# data normalization\n",
    "train_datagen = ImageDataGenerator(rescale = 1/255.) # 값을 0 ~ 1사이로 조정\n",
    "test_datagen = ImageDataGenerator(rescale = 1/255.)\n",
    "\n",
    "print(\"학습 이미지 : \")\n",
    "train_data_10_percent = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = IMAGE_SHAPE,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode = \"categorical\"\n",
    ")\n",
    "\n",
    "print(\"테스트 이미지 : \")\n",
    "test_data_10_percent = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size = IMAGE_SHAPE,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode = \"categorical\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "source": [
    "### callback 설정 (모델이 학습하는 동안 실행하는 것)\n",
    "\n",
    "#### 학습 중에 또는 학습 후에 수행할 모델에 기능을 더 추가해 주는 것!\n",
    "\n",
    "#### TensorBoard를 사용!\n",
    "#### 실험을 추적하고 여러 모델의 성능을 기록한 다음 tensorboard에서 시각적 방식으로\n",
    "모델을 비교할 수 있습니다. 같은 데이터로 여러 모델의 결과를 비교하는데 유용합니다.\n",
    "\n",
    "#### 모델 체크포인트 (Model Checkpointing) : 상황에 따라 학습을 중지하고 다시 돌아와서 계속 진행할 수 있도록 모델을 저장\n",
    "\n",
    "#### 조기 중지 (Early Stopping) : 임의의 시간동안 모델 학습을 진행시키다가 모델이 개선된 것으로 판단이 되면 학습을 자동으로 중단. 대용량 데이터셋이 있고 학습에 얼마나 오래 걸리지 모를 때 유용한 개념"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def create_tensorboard_callback(dir_name, experiment_name):\n",
    "    log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir = log_dir\n",
    "    )\n",
    "    print(f\"TensorBoard 로그 파일을 저장한 디렉토리 : {log_dir}\")\n",
    "    return tensorboard_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: tensorflow_hub in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (0.12.0)\nRequirement already satisfied: protobuf>=3.8.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tensorflow_hub) (3.16.0)\nRequirement already satisfied: numpy>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tensorflow_hub) (1.19.5)\nRequirement already satisfied: six>=1.9 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from protobuf>=3.8.0->tensorflow_hub) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_hub\n",
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resnet 50 V2\n",
    "resnet_url = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4\"\n",
    "\n",
    "# EfficientNet0\n",
    "efficientnet_url = \"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow hub URL을 가지고 와서 Keras sequential model을 생성\n",
    "\n",
    "# model_url : tensorflow hub에 존재하는 모델의 링크\n",
    "# num_classes : 출력층에서 출력 뉴런의 갯수, 대상 클래스의 수와 같아야 합니다. 기본 설정값을 10을 함\n",
    "\n",
    "# 아래 함수을 결과는 컴파일 되지 않은 keras sequential model!\n",
    "\n",
    "def create_model(model_url, num_classes = 10):\n",
    "    feature_extractor_layer = hub.KerasLayer(\n",
    "        model_url,\n",
    "        trainable = False,   # 기본 패턴을 고정\n",
    "        name = \"feature_extraction_layer\",\n",
    "        input_shape = IMAGE_SHAPE + (3, )\n",
    "    )\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        feature_extractor_layer,\n",
    "        layers.Dense(\n",
    "            num_classes, \n",
    "            activation = \"softmax\", \n",
    "            name = \"output_layer\"\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(train_data_10_percent.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "resnet_model = create_model(\n",
    "    resnet_url,\n",
    "    num_classes = train_data_10_percent.num_classes\n",
    ")\n",
    "\n",
    "# 컴파일\n",
    "resnet_model.compile(\n",
    "    loss = \"categorical_crossentropy\",\n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TensorBoard 로그 파일을 저장한 디렉토리 : tensorflow_hub/resnet50V2/20210619-105356\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 287s 12s/step - loss: 1.9194 - accuracy: 0.3413 - val_loss: 1.2304 - val_accuracy: 0.6108\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 457s 20s/step - loss: 0.9461 - accuracy: 0.7173 - val_loss: 0.9195 - val_accuracy: 0.6972\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 441s 19s/step - loss: 0.6344 - accuracy: 0.8307 - val_loss: 0.7768 - val_accuracy: 0.7452\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 501s 22s/step - loss: 0.4964 - accuracy: 0.8733 - val_loss: 0.7268 - val_accuracy: 0.7624\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 417s 18s/step - loss: 0.3981 - accuracy: 0.9013 - val_loss: 0.6966 - val_accuracy: 0.7712\n"
     ]
    }
   ],
   "source": [
    "resnet_history = resnet_model.fit(\n",
    "    train_data_10_percent,\n",
    "    epochs = 5,\n",
    "    steps_per_epoch = len(train_data_10_percent),\n",
    "    validation_data = test_data_10_percent,\n",
    "    validation_steps = len(test_data_10_percent),\n",
    "    callbacks = [\n",
    "        create_tensorboard_callback(\n",
    "            dir_name = \"tensorflow_hub\",\n",
    "            experiment_name = \"resnet50V2\"\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}