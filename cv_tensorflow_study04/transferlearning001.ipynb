{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python382jvsc74a57bd0aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## transfer learning (전이 학습)\n",
    "## transferlearning_001.ipynb"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### 최소한의 노력으로 최대의 효과를 얻고자 하는 것이 목표\n",
    "#### pypi.org에서 수 많은 라이브러리가 있는 것처럼,\n",
    "#### 분명히 다른 사람이 내가 하고자 하는 작업에 적합한 모델을 만드는데 시간을 보냈을 것이다.\n",
    "#### 누군가가 딥러닝을 위한 모델을 이미 만들어서 존재 한다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "[Tensorflow hub](https://tfhub.dev/) : 기존 모델 구성을 위한 저장소"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 전의학습의 사용이유\n",
    "#### 이미지 데이터를 구하기 어렵고, 구하는 시간도 오래걸린다.\n",
    "#### 이미지를 구할 때 귀찮은 bias가 생실 수도 있다. (내가 좋은 결과를 얻고자 하는 이미지만 보려고 한다.)\n",
    "#### 시간은 없고, 돈도 없고, 이미지는 적게 가지고 있는데 결과를 빨고 얻고 싶을때 "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_ref = zipfile.ZipFile(\"10_food_classes_10_percent.zip\", \"r\")\n",
    "zip_ref.extractall()\n",
    "zip_ref.close()\n",
    "\n",
    "# 10_food_classes_10_precent 라는 폴더가 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10_food_classes_10_percent 폴더에는 2개의 폴더와 0개의 파일이 존재한다.\n10_food_classes_10_percent/test 폴더에는 10개의 폴더와 0개의 파일이 존재한다.\n10_food_classes_10_percent/test/ice_cream 폴더에는 0개의 폴더와 250개의 파일이 존재한다.\n10_food_classes_10_percent/test/chicken_curry 폴더에는 0개의 폴더와 250개의 파일이 존재한다.\n10_food_classes_10_percent/test/steak 폴더에는 0개의 폴더와 250개의 파일이 존재한다.\n10_food_classes_10_percent/test/sushi 폴더에는 0개의 폴더와 250개의 파일이 존재한다.\n10_food_classes_10_percent/test/chicken_wings 폴더에는 0개의 폴더와 250개의 파일이 존재한다.\n10_food_classes_10_percent/test/grilled_salmon 폴더에는 0개의 폴더와 250개의 파일이 존재한다.\n10_food_classes_10_percent/test/hamburger 폴더에는 0개의 폴더와 250개의 파일이 존재한다.\n10_food_classes_10_percent/test/pizza 폴더에는 0개의 폴더와 250개의 파일이 존재한다.\n10_food_classes_10_percent/test/ramen 폴더에는 0개의 폴더와 250개의 파일이 존재한다.\n10_food_classes_10_percent/test/fried_rice 폴더에는 0개의 폴더와 250개의 파일이 존재한다.\n10_food_classes_10_percent/train 폴더에는 10개의 폴더와 0개의 파일이 존재한다.\n10_food_classes_10_percent/train/ice_cream 폴더에는 0개의 폴더와 75개의 파일이 존재한다.\n10_food_classes_10_percent/train/chicken_curry 폴더에는 0개의 폴더와 75개의 파일이 존재한다.\n10_food_classes_10_percent/train/steak 폴더에는 0개의 폴더와 75개의 파일이 존재한다.\n10_food_classes_10_percent/train/sushi 폴더에는 0개의 폴더와 75개의 파일이 존재한다.\n10_food_classes_10_percent/train/chicken_wings 폴더에는 0개의 폴더와 75개의 파일이 존재한다.\n10_food_classes_10_percent/train/grilled_salmon 폴더에는 0개의 폴더와 75개의 파일이 존재한다.\n10_food_classes_10_percent/train/hamburger 폴더에는 0개의 폴더와 75개의 파일이 존재한다.\n10_food_classes_10_percent/train/pizza 폴더에는 0개의 폴더와 75개의 파일이 존재한다.\n10_food_classes_10_percent/train/ramen 폴더에는 0개의 폴더와 75개의 파일이 존재한다.\n10_food_classes_10_percent/train/fried_rice 폴더에는 0개의 폴더와 75개의 파일이 존재한다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(\"10_food_classes_10_percent\"):\n",
    "    print(f\"{dirpath} 폴더에는 {len(dirnames)}개의 폴더와 {len(filenames)}개의 파일이 존재한다.\")\n",
    "\n",
    "# 학습은 지난번보다 10%의 데이터로 하고, 테스트는 원래의 양과 같이 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "학습 이미지 : \n",
      "Found 750 images belonging to 10 classes.\n",
      "테스트 이미지 : \n",
      "Found 2500 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# 데이터가 준비가 된 상태\n",
    "# 데이터를 분석할 준비하기\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "IMAGE_SHAPE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dir = \"10_food_classes_10_percent/train/\"\n",
    "test_dir = \"10_food_classes_10_percent/test/\"\n",
    "\n",
    "# data normalization\n",
    "train_datagen = ImageDataGenerator(rescale = 1/255.) # 값을 0 ~ 1 사이로 조정\n",
    "test_datagen = ImageDataGenerator(rescale = 1/255.)\n",
    "\n",
    "print(\"학습 이미지 : \")\n",
    "train_data_10_percent = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = IMAGE_SHAPE,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode = \"categorical\"\n",
    ")\n",
    "\n",
    "print(\"테스트 이미지 : \")\n",
    "test_data_10_percent = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size = IMAGE_SHAPE,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode = \"categorical\"\n",
    ")"
   ]
  },
  {
   "source": [
    "### callback 설정 (모델이 학습하는 동안 실행하는 것)\n",
    "\n",
    "#### 학습 중에 또는 학습 후에 수행할 모델에 기능을 더 추가해 주는 것.\n",
    "\n",
    "#### TensorBoard 사용\n",
    "#### 실험을 추적하고 여러 모델의 성능을 기록한 다음 tensorboard에서 시각적 방식으로 모델을 비교할 수 있다. 같은 데이터로 여러 모델의 결과를 비교하는데 유용하다.\n",
    "\n",
    "#### 모델 체크포인트 (Model Checkpointing) : 상황에 따라 학습을 중지하고 다시 돌아와서 계속 진행할 수 있도록 모델을 저장\n",
    "\n",
    "#### 조기 중지 (Early Stopping) : 임의의 시간동안 모델 학습을 진행시키다가 모델이 개선된 것으로 판단이 되면 학습을 자동으로 중단. 대용량 데이터셋이 있고 학습에 얼마나 오래 걸릴지 모를 때 유용한 개념\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def create_tensorboard_callback(dir_name, experiment_name):\n",
    "    log_dir = dir_name + \"/\" + experiment_name + \"/\" +datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir = log_dir\n",
    "    )\n",
    "    print(f\"TensorBoard 로그 파일을 저장한 디렉토리 : {log_dir}\")\n",
    "    return tensorboard_callback\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: tensorflow_hub in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (0.12.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tensorflow_hub) (1.19.5)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tensorflow_hub) (3.16.0)\n",
      "Requirement already satisfied: six>=1.9 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from protobuf>=3.8.0->tensorflow_hub) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_hub\n",
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resnet 50 V2\n",
    "resnet_url = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4\"\n",
    "\n",
    "# EfficientNet0\n",
    "efficientnet_url = \"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 만드는 함수\n",
    "# tensorflow hub url을 가지고 와서 keras sequential model을 생성\n",
    "# model_url : tensorflow hub에 존재하는 model의 링크\n",
    "# num_classese : 출력출에서 출력 뉴런의 갯수를 지정, 대상 클래스의 수와 같아야 한다.\n",
    "# 아래 함수의 결과는 컴파일 되지 않은 keras sequential model\n",
    "def create_model(model_url, num_classes = 10):\n",
    "    feature_extractor_layer = hub.KerasLayer(\n",
    "        model_url,\n",
    "        trainable = False,  # 기본 패턴을 고정\n",
    "        name = \"feature_extraction_layer\",\n",
    "        input_shape = IMAGE_SHAPE + (3, )\n",
    "    )\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        feature_extractor_layer,\n",
    "        layers.Dense(\n",
    "            num_classes, \n",
    "            activation = \"softmax\",\n",
    "            name = \"output_layer\"\n",
    "            )\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curves(history):\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "    accuracy = history.history[\"accuracy\"]\n",
    "    val_accuracy = history.history[\"val_accuracy\"]\n",
    "\n",
    "    epochs = range(len(history.history[\"loss\"]))\n",
    "\n",
    "    plt.plot(epochs, loss, label=\"training loss\")\n",
    "    plt.plot(epochs, val_loss, label=\"validation loss\")\n",
    "    plt.title(\"Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, accuracy, label=\"training accuracy\")\n",
    "    plt.plot(epochs, val_accuracy, label=\"validation accuracy\")\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "resnet_model = create_model(\n",
    "    resnet_url,\n",
    "    num_classes = train_data_10_percent.num_classes\n",
    ")\n",
    "\n",
    "# 컴파일\n",
    "resnet_model.compile(\n",
    "    loss = \"categorical_crossentropy\",\n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    metrics = [\"accuracy\"]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TensorBoard 로그 파일을 저장한 디렉토리 : tensorflow_hub/resnet50V2/20210619-105820\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 497s 20s/step - loss: 1.9176 - accuracy: 0.3627 - val_loss: 1.2077 - val_accuracy: 0.6108\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 440s 19s/step - loss: 0.8917 - accuracy: 0.7360 - val_loss: 0.8598 - val_accuracy: 0.7160\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 505s 22s/step - loss: 0.6001 - accuracy: 0.8493 - val_loss: 0.7456 - val_accuracy: 0.7564\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 405s 17s/step - loss: 0.4604 - accuracy: 0.8880 - val_loss: 0.6917 - val_accuracy: 0.7692\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 212s 9s/step - loss: 0.3749 - accuracy: 0.9107 - val_loss: 0.6717 - val_accuracy: 0.7752\n"
     ]
    }
   ],
   "source": [
    "resnet_history = resnet_model.fit(\n",
    "    train_data_10_percent,\n",
    "    epochs=5,\n",
    "    steps_per_epoch=len(train_data_10_percent),\n",
    "    validation_data = test_data_10_percent,\n",
    "    validation_steps=len(test_data_10_percent),\n",
    "    callbacks=[\n",
    "        create_tensorboard_callback(\n",
    "            dir_name=\"tensorflow_hub\",\n",
    "            experiment_name=\"resnet50V2\"\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(resnet_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# efficientnet 모델 생성\n",
    "efficientnet_model = create_model(\n",
    "    efficientnet_url,\n",
    "    num_classes = train_data_10_percent.num_classes\n",
    ")\n",
    "\n",
    "# 컴파일\n",
    "efficientnet_model.compile(\n",
    "    loss = \"categorical_crossentropy\",\n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    metrics = [\"accuracy\"]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TensorBoard 로그 파일을 저장한 디렉토리 : tensorflow_hub/efficientnet/20210619-113256\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 118s 5s/step - loss: 1.8608 - accuracy: 0.4213 - val_loss: 1.3148 - val_accuracy: 0.7244\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 104s 4s/step - loss: 1.0591 - accuracy: 0.7800 - val_loss: 0.8707 - val_accuracy: 0.8192\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 103s 4s/step - loss: 0.7509 - accuracy: 0.8493 - val_loss: 0.7002 - val_accuracy: 0.8384\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 103s 4s/step - loss: 0.5987 - accuracy: 0.8693 - val_loss: 0.6083 - val_accuracy: 0.8528\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 104s 4s/step - loss: 0.5074 - accuracy: 0.8840 - val_loss: 0.5562 - val_accuracy: 0.8632\n"
     ]
    }
   ],
   "source": [
    "efficientnet_history = efficientnet_model.fit(\n",
    "    train_data_10_percent,\n",
    "    epochs=5,\n",
    "    steps_per_epoch=len(train_data_10_percent),\n",
    "    validation_data = test_data_10_percent,\n",
    "    validation_steps=len(test_data_10_percent),\n",
    "    callbacks=[\n",
    "        create_tensorboard_callback(\n",
    "            dir_name=\"tensorflow_hub\",\n",
    "            experiment_name=\"efficientnet\"\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_6\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nfeature_extraction_layer (Ke (None, 1280)              4049564   \n_________________________________________________________________\noutput_layer (Dense)         (None, 10)                12810     \n=================================================================\nTotal params: 4,062,374\nTrainable params: 12,810\nNon-trainable params: 4,049,564\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "efficientnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(efficientnet_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m tensorboard.main dev upload --logdir ./tensorflow_hub/ --name ResNet50V2 --one_shot"
   ]
  }
 ]
}